import pandas as pd
import chromadb
import sys
import os
import time
import glob
from langchain_ollama import OllamaEmbeddings

# ==============================================================================
# CONFIGURACIÃ“N
# ==============================================================================
MODELO_GEMMA = "gemma:2b"
NOMBRE_COLECCION = "canciones_gemma_db"

# LÃ­mite de seguridad: procesamos mÃ¡ximo 100 canciones para que la demo sea rÃ¡pida.
# Si quieres procesar todo, cambia esto a 10000 o None (pero tardarÃ¡ mucho mÃ¡s).
LIMITE_CANCIONES = 100

# NÃºmero de canciones que devolverÃ¡ el sistema de recomendaciÃ³n
TOP_K_RESULTADOS = 5


class SistemaRecomendacion:
    def __init__(self) -> None:
        print(f"\nğŸ¤– Inicializando sistema con {MODELO_GEMMA}...")
        self.dir_actual = os.path.dirname(os.path.abspath(__file__))
        self.ruta_db = os.path.join(self.dir_actual, "chroma_db")

        try:
            # Motor de embeddings local con Gemma
            self.embeddings = OllamaEmbeddings(model=MODELO_GEMMA)

            # Cliente persistente de ChromaDB
            self.chroma_client = chromadb.PersistentClient(path=self.ruta_db)

            # ColecciÃ³n (Ã­ndice vectorial) con mÃ©trica coseno
            self.collection = self.chroma_client.get_or_create_collection(
                name=NOMBRE_COLECCION,
                metadata={"hnsw:space": "cosine"},
            )
            print("âœ… Motor vectorial listo.")
        except Exception as e:
            print(f"âŒ Error crÃ­tico inicializando: {e}")
            sys.exit(1)

    # --------------------------------------------------------------------------
    # INDEXACIÃ“N
    # --------------------------------------------------------------------------
    def encontrar_todos_los_csvs(self):
        """ Busca TODOS los archivos .csv dentro de song_lyrics_dataset/csv. AsÃ­ nos aseguramos de usar solo el dataset de Kaggle."""
        carpeta_dataset = os.path.join(self.dir_actual, "song_lyrics_dataset", "csv")
        patron = os.path.join(carpeta_dataset, "*.csv")
        archivos = glob.glob(patron)

        print(f"ğŸ” Buscando CSVs en: {carpeta_dataset}")
        print(f"ğŸ“‚ Archivos .csv encontrados: {len(archivos)}")
        for a in archivos[:5]:
            print(f"   - {os.path.basename(a)}")
        return archivos

    def indexar_datos(self) -> None:
        csvs = self.encontrar_todos_los_csvs()

        if not csvs:
            print("âŒ ERROR: No encontrÃ© ningÃºn archivo .csv.")
            print("   AsegÃºrate de descomprimir el ZIP del dataset dentro de este proyecto.")
            return

        total_procesadas = 0
        ids = []
        docs = []
        metas = []

        print(f"âš¡ Comenzando indexaciÃ³n masiva (LÃ­mite: {LIMITE_CANCIONES} canciones)...")
        start_total = time.time()

        for archivo in csvs:
            if LIMITE_CANCIONES is not None and total_procesadas >= LIMITE_CANCIONES:
                break

            print(f"   ğŸ“„ Leyendo: {os.path.basename(archivo)}...")
            try:
                # Leemos el CSV manejando errores de formato comunes
                df = pd.read_csv(
                    archivo,
                    on_bad_lines="skip",
                    encoding="utf-8",
                    engine="python",
                )

                # Normalizamos nombres de columnas a minÃºsculas y sin espacios
                df.columns = [c.lower().strip() for c in df.columns]

                # Detectamos variaciones tÃ­picas de columnas
                col_t = next(
                    (c for c in df.columns if c in ["title", "song", "track_name", "name"]),
                    None,
                )
                col_a = next(
                    (c for c in df.columns if c in ["artist", "singer", "band", "performer"]),
                    None,
                )
                col_l = next(
                    (c for c in df.columns if c in ["lyrics", "text", "lyric", "content"]),
                    None,
                )

                # Si no hay tÃ­tulo o letra, no nos sirve este archivo
                if not (col_t and col_l):
                    print(
                        f"      âš ï¸ Saltando {os.path.basename(archivo)} "
                        "(no detectÃ© columnas de TÃ­tulo/Letra)"
                    )
                    continue

                # Recorremos cada fila del CSV
                for _, row in df.iterrows():
                    if LIMITE_CANCIONES is not None and total_procesadas >= LIMITE_CANCIONES:
                        break

                    try:
                        titulo = str(row[col_t])
                        artista = str(row[col_a]) if col_a else "Unknown Artist"
                        letra = str(row[col_l])

                        # Cortamos letras gigantes para acelerar la demo
                        letra_recortada = letra[:1000]

                        # Solo procesamos si hay letra suficientemente larga
                        if len(letra_recortada) > 20:
                            texto_vector = (
                                f"Song: {titulo}. Artist: {artista}. "
                                f"Context: {letra_recortada}"
                            )

                            ids.append(f"song_{total_procesadas}")
                            docs.append(texto_vector)
                            metas.append({"titulo": titulo, "artista": artista})
                            total_procesadas += 1
                    except Exception:
                        # Si una fila viene mal formateada, simplemente la ignoramos
                        continue

            except Exception as e:
                print(f"      âŒ Error leyendo archivo {os.path.basename(archivo)}: {e}")

        if not docs:
            print("âš ï¸ No se pudieron extraer canciones vÃ¡lidas de los CSVs encontrados.")
            return

        print(f"â³ Vectorizando {len(docs)} canciones con Gemma (paciencia)...")
        try:
            vectores = self.embeddings.embed_documents(docs)
            self.collection.add(
                ids=ids,
                embeddings=vectores,
                documents=docs,
                metadatas=metas,
            )
            duracion = time.time() - start_total
            print(f"âœ… Â¡Ã‰xito! IndexaciÃ³n terminada en {duracion:.2f} segundos.")
        except Exception as e:
            print(f"âŒ Error durante la vectorizaciÃ³n o el indexado: {e}")

    # --------------------------------------------------------------------------
    # CONSULTA
    # --------------------------------------------------------------------------
    def buscar(self, consulta: str) -> None:
        print(f"\nğŸ” Buscando: '{consulta}'...")
        try:
            vector_query = self.embeddings.embed_query(consulta)
            resultados = self.collection.query(
                query_embeddings=[vector_query],
                n_results=TOP_K_RESULTADOS,
            )

            print("\nğŸ¶ RECOMENDACIONES SEMÃNTICAS:")
            print("=" * 40)

            if not resultados.get("ids") or not resultados["ids"][0]:
                print("No se encontraron coincidencias.")
                return

            for i in range(len(resultados["ids"][0])):
                titulo = resultados["metadatas"][0][i]["titulo"]
                artista = resultados["metadatas"][0][i]["artista"]
                # En Chroma, distances es 1 - similitud_coseno cuando el espacio es 'cosine'
                score = 1 - resultados["distances"][0][i]

                print(f"{i + 1}. {titulo}")
                print(f"   ğŸ‘¤ {artista}")
                print(f"   ğŸ“Š Similitud: {score:.4f}")
                print("-" * 40)
        except Exception as e:
            print(f"âŒ Error durante la bÃºsqueda: {e}")


# ==============================================================================
# PUNTO DE ENTRADA
# ==============================================================================
if __name__ == "__main__":
    app = SistemaRecomendacion()

    # Si la base estÃ¡ vacÃ­a, indexamos; si no, solo avisamos cuÃ¡ntas canciones hay
    try:
        cantidad = app.collection.count()
    except Exception:
        cantidad = 0

    if cantidad == 0:
        app.indexar_datos()
    else:
        print(f"â„¹ï¸ Base de datos cargada ({cantidad} canciones listas).")

    # Bucle interactivo de consulta
    while True:
        q = input("\n>> Describe una situaciÃ³n o sentimiento (o 'salir'): ")
        if q.lower().strip() in {"salir", "exit", "quit"}:
            print("ğŸ‘‹ Saliendo del sistema de recomendaciÃ³n.")
            break
        if q.strip():
            app.buscar(q)